{"cells":[{"cell_type":"markdown","metadata":{"id":"w_-c1nfy4za1"},"source":["# Chapter5-4"]},{"cell_type":"markdown","metadata":{"id":"OW0_dN-343vZ"},"source":["## 意味的類似度計算\n","\n","Chapter5-1～5-3までのモデルではモデルが推論した際のラベルを出力する分類タスクだが、\u003cbr\u003e\n","今回は2つの文の意味がどれだけ似ているかを算出する回帰のタスクを行う"]},{"cell_type":"markdown","metadata":{"id":"9me7CqDL5Are"},"source":["## ライブラリのインストール"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"crvsStIM2iWX"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers[ja,torch] in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (3.13.4)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (0.20.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (1.25.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (24.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (2.31.0)\n","Requirement already satisfied: tokenizers\u003c0.20,\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (0.19.1)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (0.4.3)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (4.66.2)\n","Collecting fugashi\u003e=1.0 (from transformers[ja,torch])\n","  Downloading fugashi-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (600 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.9/600.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipadic\u003c2.0,\u003e=1.0.0 (from transformers[ja,torch])\n","  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting unidic-lite\u003e=1.0.7 (from transformers[ja,torch])\n","  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting unidic\u003e=1.0.2 (from transformers[ja,torch])\n","  Downloading unidic-1.1.0.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sudachipy\u003e=0.6.6 (from transformers[ja,torch])\n","  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sudachidict-core\u003e=20220729 (from transformers[ja,torch])\n","  Downloading SudachiDict_core-20240409-py3-none-any.whl (72.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rhoknp\u003c1.3.1,\u003e=1.1.0 (from transformers[ja,torch])\n","  Downloading rhoknp-1.3.0-py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (2.2.1+cu121)\n","Collecting accelerate\u003e=0.21.0 (from transformers[ja,torch])\n","  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow\u003e=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill\u003c0.3.9,\u003e=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]\u003c=2024.3.1,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.19.3 (from transformers[ja,torch])\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: scipy\u003e=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate\u003e=0.21.0-\u003etransformers[ja,torch]) (5.9.5)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (23.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.0.5)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.9.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.19.3-\u003etransformers[ja,torch]) (4.11.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib) (1.16.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers[ja,torch]) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers[ja,torch]) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers[ja,torch]) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers[ja,torch]) (2024.2.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003etransformers[ja,torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003etransformers[ja,torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003etransformers[ja,torch]) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch-\u003etransformers[ja,torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003etransformers[ja,torch]) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch-\u003etransformers[ja,torch])\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Collecting wasabi\u003c1.0.0,\u003e=0.6.0 (from unidic\u003e=1.0.2-\u003etransformers[ja,torch])\n","  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n","Collecting plac\u003c2.0.0,\u003e=1.1.3 (from unidic\u003e=1.0.2-\u003etransformers[ja,torch])\n","  Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2023.4)\n","Requirement already satisfied: tzdata\u003e=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2024.1)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003etransformers[ja,torch]) (2.1.5)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003etransformers[ja,torch]) (1.3.0)\n","Building wheels for collected packages: ipadic, unidic, unidic-lite\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=693cf8b89e27300e13e169ba55e269e5742b7a3a5df11cdaa6d286792eaf8cb2\n","  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n","  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unidic: filename=unidic-1.1.0-py3-none-any.whl size=7406 sha256=35054beb0ab0737c2ae415b2ad8e923da96175286e476829f50863d1516b9bcd\n","  Stored in directory: /root/.cache/pip/wheels/7a/72/72/1f3d654c345ea69d5d51b531c90daf7ba14cc555eaf2c64ab0\n","  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=f1bfd35b0185f455e37b17b5ba638c6375c98cc8a68629d246ac9ae00cde644a\n","  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n","Successfully built ipadic unidic unidic-lite\n","Installing collected packages: wasabi, unidic-lite, sudachipy, plac, ipadic, xxhash, sudachidict-core, rhoknp, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fugashi, dill, unidic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, nvidia-cusolver-cu12, datasets, accelerate\n","  Attempting uninstall: wasabi\n","    Found existing installation: wasabi 1.1.2\n","    Uninstalling wasabi-1.1.2:\n","      Successfully uninstalled wasabi-1.1.2\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed accelerate-0.29.3 datasets-2.19.0 dill-0.3.8 fugashi-1.3.2 huggingface-hub-0.22.2 ipadic-1.0.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 plac-1.4.3 rhoknp-1.3.0 sudachidict-core-20240409 sudachipy-0.6.8 unidic-1.1.0 unidic-lite-1.0.8 wasabi-0.10.1 xxhash-3.4.1\n"]}],"source":["!pip install transformers[ja,torch] datasets matplotlib scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"jwDLYwgM5xo-"},"source":["## データセットの読み込み"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qUtvt5q5u9t"},"outputs":[],"source":["from pprint import pprint\n","from datasets import load_dataset\n","\n","# 学習用、検証用のデータセットの読み込み\n","train_dataset = load_dataset(\n","    \"llm-book/JGLUE\", name=\"JSTS\", split=\"train\"\n",")\n","\n","valid_dataset = load_dataset(\n","    \"llm-book/JGLUE\", name=\"JSTS\", split=\"validation\"\n",")\n","\n","# それぞれのデータセットの確認\n","pprint(train_dataset[0])\n","pprint(valid_dataset[0])"]},{"cell_type":"markdown","metadata":{"id":"LDjs_q2_6cZB"},"source":["上記2つの文の意味的類似度のスコアは`label`として格納されている\u003cbr\u003e\n","JSTSのスコアの範囲は以下の通り\u003cbr\u003e\n","`0 ～ 5`"]},{"cell_type":"markdown","metadata":{"id":"kBsmJqbh7OZA"},"source":["## トークンの分割、変換処理\n","\n","chapter5-3の`preprocess_text_pair_classification`を使用することができる"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0xm87Gi6SWp"},"outputs":[],"source":["from transformers import BatchEncoding\n","\n","def preprocess_text_pair_classification(example: dict[str, str | int]) -\u003e BatchEncoding:\n","  \"\"\" 文ペア関係予測の事例をトークナイズし、IDに変換する \"\"\"\n","\n","  encoded_example = tokenizer(\n","      example[\"sentence1\"], example[\"sentence2\"], max_length=128\n","  )\n","\n","  encoded_example[\"labels\"] = example[\"label\"]\n","  return encoded_example"]},{"cell_type":"markdown","metadata":{"id":"0G-qQ1d47dkY"},"source":["## モデルの定義"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3ozVHvl7JwX"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer\n","\n","model_name = \"cl-tohoku/bert-base-japanese-v3\"\n","\n","# モデルの読み込み\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=1, # 今回はスコアのみなのでラベルは一つになる\n","    problem_type=\"regression\" # これが回帰タスクを解くためのモデルであることを指定\n",")\n","\n","# トークナイザの読み込み\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"markdown","metadata":{"id":"gZphAxxZ8o1n"},"source":["## 回帰タスク用の評価関数を定義\n","2種類の相関係数を実装\n","\n","- ピアソンの相関係数\u003cbr\u003e\n","2つの変数間の線形相関を測定する指標\n","\n","- スピアマンの順位相関係数\u003cbr\u003e\n","表す指標は上記と同じ。しかし順位関係のみを考慮して値を算出する\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rC2mXxkx8Kfy"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import pearsonr, spearmanr\n","\n","def compute_correlation_metrics(eval_pred: tuple[np.ndarray, np.ndarray]) -\u003e dict[str, float]:\n","  \"\"\" 予測スコア、正解スコアから各種相関係数を計算する \"\"\"\n","\n","\n","  predictions, labels = eval_pred\n","\n","  predictions = predictions.squeeze(1) # サイズが1の次元をすべて削除\n","\n","  return {\n","      \"pearsonr\": pearsonr(predictions, labels).statistic,\n","      \"spearmanr\": spearmanr(predictions, labels).statistic\n","  }\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"F2ql09PhDLMd"},"source":["## データの前処理"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0Mv1rJjC2CH"},"outputs":[],"source":["encoded_train_dataset = train_dataset.map(\n","    preprocess_text_pair_classification,\n","    remove_columns=train_dataset.column_names\n",")\n","\n","encoded_valid_dataset = valid_dataset.map(\n","    preprocess_text_pair_classification,\n","    remove_columns=valid_dataset.column_names\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQV8a3dzC-r1"},"outputs":[],"source":["# データの確認\n","print(encoded_train_dataset)\n","print(encoded_valid_dataset)"]},{"cell_type":"markdown","metadata":{"id":"wJHqBj9HEqvs"},"source":["## ミニバッチの構築"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWstIpEnENB-"},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANgJlrx4E1Y_"},"outputs":[],"source":["batch_inputs = data_collator(encoded_train_dataset[0:4])\n","\n","pprint({name: tensor.size() for name, tensor in batch_inputs.items()})"]},{"cell_type":"markdown","metadata":{"id":"ijWNlZIyFboj"},"source":["## 学習の実行"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efcKbV8JE-s7"},"outputs":[],"source":["# 各種パラメータを設定する\n","from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/Learning_LLM/chapter5/checkpoint\", # 結果を保存するフォルダ\n","    per_device_train_batch_size=32, # 学習時のバッチサイズ\n","    per_device_eval_batch_size=32, # 評価時のバッチサイズ\n","    learning_rate=2e-5, # 学習率\n","    lr_scheduler_type=\"linear\", # 学習率スケジュラーの種類\n","    warmup_ratio=0.1, # 学習率のウォームアップの長さを指定\n","    num_train_epochs=3, # エポック数\n","    save_strategy=\"epoch\", # チェックポイントの保存のタイミング (今回は1エポック毎に行う)\n","    logging_strategy=\"epoch\", # ロギングのタイミング (1エポック毎)\n","    evaluation_strategy=\"epoch\", # 検証セットによる評価のタイミング(1エポック毎)\n","    load_best_model_at_end=True, # 学習後に最良のモデルをロードさせる\n","    metric_for_best_model=\"pearsonr\", # 最良のモデルを決定する際の評価指標\n","    fp16=True, # 自動混合制度演算を有効にする\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMbC0iboFnf3"},"outputs":[],"source":["# 学習の開始\n","from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model.to(\"cuda\"),\n","    train_dataset=encoded_train_dataset,\n","    eval_dataset=encoded_valid_dataset,\n","    data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_correlation_metrics\n",")\n","\n","trainer.train()\n","# trainer.save_model(\"/content/drive/MyDrive/Learning_LLM/chapter5/model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snfA2yq2Fx6b"},"outputs":[],"source":["# もでる、トークナイザーの保存\n","trainer.save_model(\"/content/drive/MyDrive/Learning_LLM/chapter5/model\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/Learning_LLM/chapter5/model\")"]},{"cell_type":"markdown","metadata":{"id":"F9sWN3SX2Zl3"},"source":["## 推論の実行"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YXZ5NujY2dx0"},"outputs":[],"source":["# モデルの推論のみを行うときは必ず実行する\n","from pprint import pprint\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    Trainer\n",")\n","\n","# モデル、トークナイザを読み込む\n","model_name = \"./drive/MyDrive/Learning_LLM/chapter5/model\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ac6LxyATSO0H"},"outputs":[],"source":["# データセットを準備する\n","valid_dataset = load_dataset(\n","    \"llm-book/JGLUE\", name=\"JSTS\", split=\"validation\"\n",")\n","\n","# データセットをエンコーディングする\n","encoded_valid_dataset = valid_dataset.map(\n","    preprocess_text_pair_classification,\n","    remove_columns=valid_dataset.column_names\n",")\n","\n","# 評価の実行\n","trainer = Trainer(\n","  model=model,\n","  eval_dataset=encoded_valid_dataset,\n","  data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n","  compute_metrics=compute_correlation_metrics\n",")\n","\n","eval_metrics = trainer.evaluate()\n","pprint(eval_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1m14ZU4CSzsF"},"outputs":[],"source":["# pipelineを使ってモデルを読み込む\n","from transformers import pipeline\n","\n","text_sim_pipeline = pipeline(\n","    model=\"your model\",\n","    function_to_apply=\"none\" # 出力に適用する関数を指定する\n",")\n","\n","text1 = input(\"文章を入力: \")\n","text2 = input(\"文章を入力: \")\n","\n","print(text_sim_pipeline({\"text\": text1, \"text_pair\": text2})[\"score\"])"]},{"cell_type":"markdown","metadata":{"id":"TXWDkbGLebRI"},"source":["function_to_apply \u003cbr\u003e\n","指定していないときはデフォルトでシグモイド関数が適用される。\u003cbr\u003e\n","これによってスコアのスケールが0から1の範囲に変換されてしまう。\u003cbr\u003e\n","今回のスコアの範囲は0から5までなので、noneを設定する必要がある"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbMogvFNe_HI"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO2L48lAD17lgEWJL9UktAc","gpuType":"T4","mount_file_id":"17AtiLutrNEzcaIa1Ha4mIbryvHjLa0UX","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}